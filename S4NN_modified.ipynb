{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "S4NN_modified.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Szy4SZVyznHR"
      },
      "source": [
        "# S4NN\n",
        "*The implementation of the supervied spiking neural network named S4NN presented in  \"S4NN: temporal backpropagation for spiking neural networks with one spike per neuron\"  by S. R. Kheradpisheh and T. Masquelier.*\n",
        "\n",
        "*The paper is availbale at:* https://arxiv.org/abs/1910.09495 \n",
        "\n",
        "**Important points:**\n",
        "*   To enable GPU on Google CoLab, you should go to the Edit > Notebook Setting menue and set the Hardware Accelerator to GPU.\n",
        "*   To work on MNIST, you should unzip the MNIST.zip and upload the folder on your Google Drive account.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uvx78e27udh7",
        "colab": {}
      },
      "source": [
        "\n",
        "# Imports\n",
        "from __future__ import division\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cupy as cp # You need to have a CUDA-enabled GPU to use this package!\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WuGhViCYim0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A=pd.read_csv(\"train_data.csv\")\n",
        "B=pd.read_csv(\"train_data_labels.csv\")\n",
        "C=pd.read_csv(\"data_train_test.csv\")\n",
        "D=pd.read_csv(\"y_test_labels.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiQCLGL2Yijj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_prev=A.values\n",
        "x_train_labels_prev=B.values\n",
        "x_test_prev=C.values\n",
        "x_test_labels_prev=D.values"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j_EeGveguknc",
        "colab": {}
      },
      "source": [
        "#Parameter setting\n",
        "thr = [100, 100, 100]   #The threshold of hidden and output neurons\n",
        "lr = [.2,.2,.2]    #The learning rate of hidden and ouput neurons\n",
        "lamda=[0.000001,0.000001,0.000001]   # The regularization penalty for hidden and ouput neurons\n",
        "b=[5,48,96]    #The upper bound of wight initializations for hidden and ouput neurons\n",
        "a=[0,0,0]    #The lower bound of wight initializations for hidden and ouput neurons\n",
        "Nepoch = 3    #The maximum number of training epochs\n",
        "NumOfClasses = 6   #Number of classes\n",
        "Nlayers = 3    #Number of layers\n",
        "NhidenNeurons1 =40   #Number of hidden neurons\n",
        "NhidenNeurons2 =40   #Number of hidden neurons\n",
        "Dropout=[0.1,0.1,0.1] \n",
        "tmax = 256   #Simulatin time\n",
        "gamma=3 #The gamma parameter in the relative target firing calculation\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oj1LWIXkuscP",
        "colab": {}
      },
      "source": [
        "#General settings\n",
        "loading=False   # Set it as True if you want to load a pretrained model\n",
        "LoadFrom= \"weights.npy\"  # The pretrained model\n",
        "saving=False    # Set it as True if you want to save the trained model\n",
        "best_perf=0\n",
        "Nnrn = [NhidenNeurons1,NhidenNeurons2, NumOfClasses]   # Number of neurons at hidden and output layers\n",
        "cats=[4,1,0,2,3,5]   # Reordering the categories"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tkiwnLYAuwdH",
        "colab": {}
      },
      "source": [
        "#General variables\n",
        "x_train=[]  # To keep training images\n",
        "x_train_labels=[]  # To keep training labels\n",
        "x_test=[]  # To keep test images\n",
        "x_test_labels=[]  # To keep test labels\n",
        "W=[] #To hold the weights of hidden and output layers\n",
        "firingTime=[] #To hold the firing times of hidden and output layers\n",
        "Spikes=[] #To hold the spike trains of hidden and output layers\n",
        "X=[] #To be used in converting firing times to spike trains\n",
        "target = cp.zeros([NumOfClasses]) # To keep the target firing times of current image\n",
        "FiringFrequency=[] # to count number of spikes each neuron emits during an epoch"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iXDFUNLnu5ce",
        "colab": {}
      },
      "source": [
        "#loading dataset\n",
        "   \n",
        "for i in range(len(x_train_labels_prev)):\n",
        "    if x_train_labels_prev[i] in cats:\n",
        "        x_train.append(np.floor(x_train_prev[i].reshape(10,10)).astype(int))\n",
        "        x_train_labels.append(cats.index(x_train_labels_prev[i]))\n",
        "  \n",
        "\n",
        "for i in range(len(x_test_labels_prev)):\n",
        "    if x_test_labels_prev[i] in cats:\n",
        "        #images_test.append(TTT[i].reshape(28,28).astype(int))            \n",
        "        x_test.append(np.floor(x_test_prev[i].reshape(10,10)).astype(int)) \n",
        "        x_test_labels.append(cats.index(x_test_labels_prev[i]))\n",
        "                        \n",
        "\n",
        "x_train = cp.asarray(x_train)\n",
        "x_train_labels = cp.asarray(x_train_labels)\n",
        "x_test = cp.asarray(x_test)\n",
        "x_test_labels= cp.asarray(x_test_labels)  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HQ1okDAlvBDb",
        "colab": {}
      },
      "source": [
        "#Building the model\n",
        "layerSize=[[x_train[0].shape[0],x_train[0].shape[1]], [NhidenNeurons1,1],[NhidenNeurons1,1],[NumOfClasses,1]]    \n",
        "x = cp.mgrid[0:layerSize[0][0],0:layerSize[0][1]]# To be used in converting raw image into a spike image\n",
        "SpikeImage = cp.zeros((layerSize[0][0],layerSize[0][1], tmax+1)) # To keep spike image\n",
        "\n",
        "# Initializing the network\n",
        "np.random.seed(0)\n",
        "for layer in range(Nlayers):\n",
        "    W.append(cp.asarray((b[layer] - a[layer]) * np.random.random_sample((Nnrn[layer], layerSize[layer][0],layerSize[layer][1])) + a[layer])) \n",
        "    firingTime.append(cp.asarray(np.zeros(Nnrn[layer])))\n",
        "    Spikes.append(cp.asarray(np.zeros((layerSize[layer+1][0],layerSize[layer+1][1],tmax+1))))\n",
        "    X.append(cp.asarray(np.mgrid[0:layerSize[layer+1][0],0:layerSize[layer+1][1]]))\n",
        "\n",
        "SpikeList=[SpikeImage]+Spikes"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5IudJtbbe7c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ff7c28b-1342-408b-a328-5cf5f6e3e2e5"
      },
      "source": [
        "layerSize"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[10, 10], [40, 1], [40, 1], [6, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ogSqG-UTww-F"
      },
      "source": [
        "**To evaluate the pretrained model you should skip the cell below and run the next cell**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hwW46lALvPJm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "e32312f9-9df4-4303-d88e-5fba41ad4881"
      },
      "source": [
        "# Start learning\n",
        "for epoch in range(Nepoch):\n",
        "    start_time = time.time()\n",
        "    correct=cp.zeros(NumOfClasses)\n",
        "    FiringFrequency=cp.zeros((NhidenNeurons1,NhidenNeurons2))\n",
        "\n",
        "    # Start an epoch\n",
        "    for iteration in range(len(x_train)): \n",
        "        #converting input image into spiking image\n",
        "        SpikeImage[:,:,:]=0\n",
        "        SpikeImage[x[0],x[1],x_train[iteration]] = 1\n",
        "\n",
        "        #Feedforward path\n",
        "        for layer in range(Nlayers):\n",
        "            Voltage=cp.cumsum(cp.tensordot(W[layer], SpikeList[layer]),1) # Computing the voltage\n",
        "            Voltage[:,tmax]=thr[layer]+1 # Forcing the fake spike\n",
        "            firingTime[layer] = cp.argmax(Voltage>thr[layer],axis=1).astype(float)+1   # Findign the first threshold crossing  \n",
        "            firingTime[layer][firingTime[layer]>tmax]=tmax # Forcing the fake spike\n",
        "                \n",
        "            Spikes[layer][:,:,:]=0   \n",
        "            Spikes[layer][X[layer][0],X[layer][1],firingTime[layer].reshape(Nnrn[layer],1).astype(int)]=1 #converting firing times to spikes\n",
        "\n",
        "        \n",
        "        FiringFrequency =  FiringFrequency + (firingTime[0] < tmax) # FiringFrequency is used to find dead neurons\n",
        "\n",
        "        #Computing the relative target firing times\n",
        "        winner=np.argmin(firingTime[Nlayers-2]) \n",
        "        minFiring=min(firingTime[layer])\n",
        "        if minFiring == tmax:          \n",
        "            target[:,:]=minFiring\n",
        "            target[x_train_labels[iteration]]=minFiring-gamma\n",
        "            target=target.astype(int)\n",
        "        else:\n",
        "            target[:]=firingTime[layer][:]\n",
        "            toChange=(firingTime[layer]-minFiring)<gamma\n",
        "            target[toChange]=min(minFiring+gamma,tmax)\n",
        "            target[x_train_labels[iteration]]=minFiring\n",
        "          \n",
        "\n",
        "        #Backward path\n",
        "        layer= Nlayers-1 # Output layer\n",
        "\n",
        "        delta_o=(target-firingTime[layer])/tmax # Error in the ouput layer\n",
        "\n",
        "        #Gradient normalization\n",
        "        norm=cp.linalg.norm(delta_o)\n",
        "        if (norm!=0):\n",
        "            delta_o=delta_o/norm\n",
        "            \n",
        "        if Dropout[layer]>0.1:\n",
        "                firingTime[layer][cp.asarray(np.random.permutation(Nnrn[layer])[:Dropout[layer]])]=tmax\n",
        "        \n",
        "        # Updating hidden-output weights\n",
        "        hasFired_o=firingTime[layer-2]<firingTime[layer][:, cp.newaxis] # To find which hidden neurons has fired before the ouput neurons\n",
        "        W[layer][:,:,0]-=(delta_o[:, cp.newaxis]*hasFired_o*lr[layer]) # Update hidden-ouput weights \n",
        "        W[layer]-=lr[layer]*lamda[layer]*W[layer] # Weight regularization\n",
        "\n",
        "        # Backpropagating error to hidden neurons\n",
        "        delta_h=(cp.multiply(delta_o[:, cp.newaxis]*hasFired_o, W[layer][:,:,0])).sum(axis=0) #Backpropagated errors from ouput layer to hidden layer\n",
        "        \n",
        "\n",
        "        layer= Nlayers-2 # Hidden layer     \n",
        "        \n",
        "        #Gradient normalization\n",
        "        norm=cp.linalg.norm(delta_h)\n",
        "        if (norm!=0):\n",
        "            delta_h=delta_h/norm\n",
        "        # Updating input-hidden weights\n",
        "        hasFired_h=x_train[iteration]<firingTime[layer][:, cp.newaxis, cp.newaxis] # To find which input neurons has fired before the hidden neurons\n",
        "        W[layer]-=lr[layer]*delta_h[:, cp.newaxis, cp.newaxis]*hasFired_h # Update input-hidden weights \n",
        "        W[layer]-=lr[layer]*lamda[layer]*W[layer] # Weight regularization\n",
        "\n",
        "    #Evaluating on test samples\n",
        "    correct=0 \n",
        "    for iteration in range(len(x_test)):        \n",
        "        SpikeImage[:,:,:]=0\n",
        "        SpikeImage[x[0],x[1],x_test[iteration]] = 1\n",
        "        for layer in range(Nlayers):\n",
        "            Voltage=cp.cumsum(cp.tensordot(W[layer], SpikeList[layer]),1)\n",
        "            Voltage[:,tmax]=thr[layer]+1\n",
        "            firingTime[layer] = cp.argmax(Voltage>thr[layer],axis=1).astype(float)+1     \n",
        "            firingTime[layer][firingTime[layer]>tmax]=tmax\n",
        "            Spikes[layer][:,:,:]=0   \n",
        "            Spikes[layer][X[layer][0],X[layer][1],firingTime[layer].reshape(Nnrn[layer],1).astype(int)]=1\n",
        "        minFiringTime=firingTime[Nlayers-1].min()\n",
        "        if minFiringTime==tmax:\n",
        "            V=np.argmax(Voltage[:,tmax-3])\n",
        "            if V==x_test_labels[iteration]:\n",
        "              correct+=1\n",
        "        else:\n",
        "            if firingTime[layer][x_test_labels[iteration]]==minFiringTime:\n",
        "                correct+=1           \n",
        "    testPerf=correct/len(x_test)\n",
        "   \n",
        "   \n",
        "    #Evaluating on train samples\n",
        "    correct=0 \n",
        "    for iteration in range(len(x_train)):        \n",
        "        SpikeImage[:,:,:]=0\n",
        "        SpikeImage[x[0],x[1],x_train[iteration]] = 1\n",
        "        for layer in range(Nlayers):\n",
        "            Voltage=cp.cumsum(cp.tensordot(W[layer], SpikeList[layer]),1)\n",
        "            Voltage[:,tmax]=thr[layer]+1\n",
        "            firingTime[layer] = cp.argmax(Voltage>thr[layer],axis=1).astype(float)+1     \n",
        "            firingTime[layer][firingTime[layer]>tmax]=tmax      \n",
        "            Spikes[layer][:,:,:]=0   \n",
        "            Spikes[layer][X[layer][0],X[layer][1],firingTime[layer].reshape(Nnrn[layer],1).astype(int)]=1               \n",
        "        minFiringTime=firingTime[Nlayers-1].min()\n",
        "        if minFiringTime==tmax:\n",
        "            V=np.argmax(Voltage[:,tmax-3])\n",
        "            if V==x_train_labels[iteration]:\n",
        "              correct+=1\n",
        "        else:\n",
        "            if firingTime[layer][x_train_labels[iteration]]==minFiringTime:\n",
        "                correct+=1\n",
        "    trainPerf=correct/len(x_train)  \n",
        "\n",
        "    \n",
        "    print('epoch= ', epoch, 'Perf_train= ',trainPerf, 'Perf_test= ',testPerf)\n",
        "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "        \n",
        "    #To save the weights\n",
        "    if saving:\n",
        "      np.save(\"weights\", W, allow_pickle=True)\n",
        "      if testPerf>best_perf:\n",
        "        np.save(\"weights_best\", W, allow_pickle=True)\n",
        "        best_perf=val\n",
        "\n",
        "    #To find and reset dead neurons    \n",
        "    ResetCheck = FiringFrequency <0.001*len(x_train)    \n",
        "    ToReset = [i for i in range(NhidenNeurons) if ResetCheck[i]]\n",
        "    for i in ToReset:\n",
        "         W[0][i]=cp.asarray((b[0] - a[0]) * np.random.random_sample((layerSize[0][0],layerSize[0][1])) + a[0]) #r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f28686b0a744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Updating input-hidden weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mhasFired_h\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mfiringTime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# To find which input neurons has fired before the hidden neurons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdelta_h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhasFired_h\u001b[0m \u001b[0;31m# Update input-hidden weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Weight regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.ndarray.__isub__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy.core._kernel.ufunc.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/core/_routines_manipulation.pyx\u001b[0m in \u001b[0;36mcupy.core._routines_manipulation._broadcast_core\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (40, 40, 10), (40, 10, 10), (40, 40, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tFtyvkm_wmHs"
      },
      "source": [
        "**To evaluate the pretrained model you can run the cell below.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MUjogm1bvxcb",
        "colab": {},
        "outputId": "91462f89-42e6-4b7a-9977-245f113e5adb"
      },
      "source": [
        "#Evaluating the pretrained model\n",
        "LoadFrom= \"/content/gdrive/My Drive/weights_pretrained.npy\"  # The pretrained model\n",
        "W=np.load(LoadFrom, allow_pickle=True)\n",
        "\n",
        "correct=0 \n",
        "for iteration in range(len(images_test)):        \n",
        "    SpikeImage[:,:,:]=0\n",
        "    SpikeImage[x[0],x[1],images_test[iteration]] = 1\n",
        "    for layer in range(Nlayers):\n",
        "        Voltage=cp.cumsum(cp.tensordot(W[layer], SpikeList[layer]),1)\n",
        "        Voltage[:,tmax]=thr[layer]+1\n",
        "        firingTime[layer] = cp.argmax(Voltage>thr[layer],axis=1).astype(float)+1     \n",
        "        firingTime[layer][firingTime[layer]>tmax]=tmax\n",
        "        Spikes[layer][:,:,:]=0   \n",
        "        Spikes[layer][X[layer][0],X[layer][1],firingTime[layer].reshape(Nnrn[layer],1).astype(int)]=1\n",
        "    minFiringTime=firingTime[Nlayers-1].min()\n",
        "    if minFiringTime==tmax:\n",
        "        V=np.argmax(Voltage[:,tmax-3])\n",
        "        if V==labels_test[iteration]:\n",
        "          correct+=1\n",
        "    else:\n",
        "        if firingTime[layer][labels_test[iteration]]==minFiringTime:\n",
        "            correct+=1           \n",
        "testPerf=correct/len(images_test)\n",
        "print('Perf_test= ',testPerf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-8c7e3f660a3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Evaluating the pretrained model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mLoadFrom\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"/content/gdrive/My Drive/weights_pretrained.npy\"\u001b[0m  \u001b[1;31m# The pretrained model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLoadFrom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ-JSGHG3b-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #Start learning\n",
        "for epoch in range(Nepoch):\n",
        "    start_time = time.time()\n",
        "    correct=cp.zeros(NumOfClasses)\n",
        "    FiringFrequency=cp.zeros((NhidenNeurons))\n",
        "\n",
        "    # Start an epoch\n",
        "    for iteration in range(len(x_train)): \n",
        "        #converting input image into spiking image\n",
        "        SpikeImage[:,:,:]=0\n",
        "        SpikeImage[x[0],x[1],x_train[iteration]] = 1\n",
        "\n",
        "        #Feedforward path\n",
        "        for layer in range(Nlayers):\n",
        "            Voltage=cp.cumsum(cp.tensordot(W[layer], SpikeList[layer]),1) # Computing the voltage\n",
        "            Voltage[:,tmax]=thr[layer]+1 # Forcing the fake spike\n",
        "            firingTime[layer] = cp.argmax(Voltage>thr[layer],axis=1).astype(float)+1   # Finding the first threshold crossing  \n",
        "            firingTime[layer][firingTime[layer]>tmax]=tmax # Forcing the fake spike\n",
        "                \n",
        "            Spikes[layer][:,:,:]=0   \n",
        "            Spikes[layer][X[layer][0],X[layer][1],firingTime[layer].reshape(Nnrn[layer],1).astype(int)]=1 #converting firing times to spikes\n",
        "\n",
        "        \n",
        "        FiringFrequency =  FiringFrequency + (firingTime[0] < tmax) # FiringFrequency is used to find dead neurons\n",
        "\n",
        "        #Computing the relative target firing times\n",
        "        winner=np.argmin(firingTime[Nlayers-1]) \n",
        "        minFiring=min(firingTime[layer])\n",
        "        if minFiring == tmax:          \n",
        "            target[:]=minFiring\n",
        "            target[x_train_labels[iteration]]=minFiring-gamma\n",
        "            target=target.astype(int)\n",
        "        else:\n",
        "            target[:]=firingTime[layer][:]\n",
        "            toChange=(firingTime[layer]-minFiring)<gamma\n",
        "            target[toChange]=min(minFiring+gamma,tmax)\n",
        "            target[x_train_labels[iteration]]=minFiring\n",
        "          \n",
        "\n",
        "        #Backward path\n",
        "        layer= Nlayers-1 # Output layer\n",
        "\n",
        "        delta_o=(target-firingTime[layer])/tmax # Error in the ouput layer\n",
        "\n",
        "        #Gradient normalization\n",
        "        norm=cp.linalg.norm(delta_o)\n",
        "        if (norm!=0):\n",
        "            delta_o=delta_o/norm\n",
        "            \n",
        "        if Dropout[layer]>0:\n",
        "                firingTime[layer][cp.asarray(np.random.permutation(Nnrn[layer])[:Dropout[layer]])]=tmax\n",
        "        \n",
        "        # Updating hidden-output weights\n",
        "        hasFired_o=firingTime[layer-1]<firingTime[layer][:, cp.newaxis] # To find which hidden neurons has fired before the ouput neurons\n",
        "        W[layer][:,:,0]-=(delta_o[:, cp.newaxis]*hasFired_o*lr[layer]) # Update hidden-ouput weights \n",
        "        W[layer]-=lr[layer]*lamda[layer]*W[layer] # Weight regularization\n",
        "\n",
        "        # Backpropagating error to hidden neurons\n",
        "        delta_h=(cp.multiply(delta_o[:, cp.newaxis]*hasFired_o, W[layer][:,:,0])).sum(axis=0) #Backpropagated errors from ouput layer to hidden layer\n",
        "        \n",
        "\n",
        "        layer= Nlayers-2 # Hidden layer     \n",
        "        \n",
        "        #Gradient normalization\n",
        "        norm=cp.linalg.norm(delta_h)\n",
        "        if (norm!=0):\n",
        "            delta_h=delta_h/norm\n",
        "        # Updating input-hidden weights\n",
        "        hasFired_h=x_train[iteration]<firingTime[layer][:, cp.newaxis, cp.newaxis] # To find which input neurons has fired before the hidden neurons\n",
        "        W[layer]-=lr[layer]*delta_h[:, cp.newaxis, cp.newaxis]*hasFired_h # Update input-hidden weights \n",
        "        W[layer]-=lr[layer]*lamda[layer]*W[layer] # Weight regularization\n",
        "\n",
        "    #Evaluating on test samples\n",
        "    correct=0 \n",
        "    for iteration in range(len(x_test)):        \n",
        "        SpikeImage[:,:,:]=0\n",
        "        SpikeImage[x[0],x[1],x_test[iteration]] = 1\n",
        "        for layer in range(Nlayers):\n",
        "            Voltage=cp.cumsum(cp.tensordot(W[layer], SpikeList[layer]),1)\n",
        "            Voltage[:,tmax]=thr[layer]+1\n",
        "            firingTime[layer] = cp.argmax(Voltage>thr[layer],axis=1).astype(float)+1     \n",
        "            firingTime[layer][firingTime[layer]>tmax]=tmax\n",
        "            Spikes[layer][:,:,:]=0   \n",
        "            Spikes[layer][X[layer][0],X[layer][1],firingTime[layer].reshape(Nnrn[layer],1).astype(int)]=1\n",
        "        minFiringTime=firingTime[Nlayers-1].min()\n",
        "        if minFiringTime==tmax:\n",
        "            V=np.argmax(Voltage[:,tmax-3])\n",
        "            if V==x_test_labels[iteration]:\n",
        "              correct+=1\n",
        "        else:\n",
        "            if firingTime[layer][x_test_labels[iteration]]==minFiringTime:\n",
        "                correct+=1           \n",
        "    testPerf=correct/len(x_test)\n",
        "\n",
        "    correct=0 \n",
        "    for iteration in range(len(images)):        \n",
        "        SpikeImage[:,:,:]=0\n",
        "        SpikeImage[x[0],x[1],images[iteration]] = 1\n",
        "        for layer in range(Nlayers):\n",
        "            Voltage=cp.cumsum(cp.tensordot(W[layer], SpikeList[layer]),1)\n",
        "            Voltage[:,tmax]=thr[layer]+1\n",
        "            firingTime[layer] = cp.argmax(Voltage>thr[layer],axis=1).astype(float)+1     \n",
        "            firingTime[layer][firingTime[layer]>tmax]=tmax      \n",
        "            Spikes[layer][:,:,:]=0   \n",
        "            Spikes[layer][X[layer][0],X[layer][1],firingTime[layer].reshape(Nnrn[layer],1).astype(int)]=1               \n",
        "        minFiringTime=firingTime[Nlayers-1].min()\n",
        "        if minFiringTime==tmax:\n",
        "            V=np.argmax(Voltage[:,tmax-3])\n",
        "            if V==labels[iteration]:\n",
        "              correct+=1\n",
        "        else:\n",
        "            if firingTime[layer][labels[iteration]]==minFiringTime:\n",
        "                correct+=1\n",
        "    trainPerf=correct/len(images)  \n",
        "\n",
        "    \n",
        "    print('epoch= ', epoch, 'Perf_train= ',trainPerf, 'Perf_test= ',testPerf)\n",
        "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "        \n",
        "    #To save the weights\n",
        "    if saving:\n",
        "      np.save(\"weights\", W, allow_pickle=True)\n",
        "      if testPerf>best_perf:\n",
        "        np.save(\"weights_best\", W, allow_pickle=True)\n",
        "        best_perf=val\n",
        "\n",
        "    #To find and reset dead neurons    \n",
        "    ResetCheck = FiringFrequency <0.001*len(images)    \n",
        "    ToReset = [i for i in range(NhidenNeurons) if ResetCheck[i]]\n",
        "    for i in ToReset:\n",
        "         W[0][i]=cp.asarray((b[0] - a[0]) * np.random.random_sample((layerSize[0][0],layerSize[0][1])) + a[0]) #r"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}