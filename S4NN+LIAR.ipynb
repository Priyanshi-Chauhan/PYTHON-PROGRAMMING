{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S4NN+LIAR.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABzxecPGiv3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "from __future__ import division\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cupy as cp # You need to have a CUDA-enabled GPU to use this package!\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_HDNNdmjRTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A=pd.read_csv(\"train_data.csv\")\n",
        "B=pd.read_csv(\"train_data_labels.csv\")\n",
        "C=pd.read_csv(\"data_train_test.csv\")\n",
        "D=pd.read_csv(\"y_test_labels.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR_iCInyjaSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_prev=A.values\n",
        "x_train_labels_prev=B.values\n",
        "x_test_prev=C.values\n",
        "x_test_labels_prev=D.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1juYkOXi7Ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parameter setting\n",
        "thr = [100, 100]   #The threshold of hidden and output neurons\n",
        "lr = [.2,.2]    #The learning rate of hidden and ouput neurons\n",
        "lamda=[0.000001,0.000001]   # The regularization penalty for hidden and ouput neurons\n",
        "b=[5,48]    #The upper bound of wight initializations for hidden and ouput neurons\n",
        "a=[0,0]    #The lower bound of wight initializations for hidden and ouput neurons\n",
        "Nepoch = 40    #The maximum number of training epochs\n",
        "NumOfClasses = 6    #Number of classes\n",
        "Nlayers = 2    #Number of layers\n",
        "NhidenNeurons =400   #Number of hidden neurons\n",
        "Dropout=[0,0] \n",
        "tmax = 256   #Simulatin time\n",
        "GrayLevels=255 #Image GrayLevels\n",
        "gamma=3 #The gamma parameter in the relative target firing calculation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia3lyO-Sjf2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#General settings\n",
        "loading=False   # Set it as True if you want to load a pretrained model\n",
        "#LoadFrom= \"/content/gdrive/My Drive/weights.npy\"  # The pretrained model\n",
        "saving=False    # Set it as True if you want to save the trained model\n",
        "best_perf=0\n",
        "Nnrn = [NhidenNeurons, NumOfClasses]   # Number of neurons at hidden and output layers\n",
        "cats=[2,0,3,5,4,1]   # Reordering the categories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XV-1u2cjjGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#General variables\n",
        "x_train=[]  # To keep training images\n",
        "x_train_labels=[]  # To keep training labels\n",
        "x_test=[]  # To keep test images\n",
        "x_test_labels=[]  # To keep test labels\n",
        "W=[] #To hold the weights of hidden and output layers\n",
        "firingTime=[] #To hold the firing times of hidden and output layers\n",
        "Spikes=[] #To hold the spike trains of hidden and output layers\n",
        "X=[] #To be used in converting firing times to spike trains\n",
        "target = cp.zeros([NumOfClasses]) # To keep the target firing times of current image\n",
        "FiringFrequency=[] # to count number of spikes each neuron emits during an epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOU1mL8Xj7k0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading dataset\n",
        "   \n",
        "for i in range(len(x_train_labels_prev)):\n",
        "    if x_train_labels_prev[i] in cats:\n",
        "        x_train.append(np.floor(x_train_prev[i].reshape(21,21)).astype(int))\n",
        "        x_train_labels.append(cats.index(x_train_labels_prev[i]))\n",
        "  \n",
        "\n",
        "for i in range(len(x_test_labels_prev)):\n",
        "    if x_test_labels_prev[i] in cats:\n",
        "        #images_test.append(TTT[i].reshape(28,28).astype(int))            \n",
        "        x_test.append(np.floor(x_test_prev[i].reshape(21,21)).astype(int)) \n",
        "        x_test_labels.append(cats.index(x_test_labels_prev[i]))\n",
        "                        \n",
        "\n",
        "x_train = cp.asarray(x_train)\n",
        "x_train_labels = cp.asarray(x_train_labels)\n",
        "x_test = cp.asarray(x_test)\n",
        "x_test_labels= cp.asarray(x_test_labels)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNbIbAmKskjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Building the model\n",
        "layerSize=[[x_train[0].shape[0],x_train[0].shape[1]], [NhidenNeurons,1],[NumOfClasses,1]]    \n",
        "x = cp.mgrid[0:layerSize[0][0],0:layerSize[0][1]]# To be used in converting raw image into a spike image\n",
        "SpikeImage = cp.zeros((layerSize[0][0],layerSize[0][1], tmax+1)) # To keep spike image\n",
        "\n",
        "# Initializing the network\n",
        "np.random.seed(0)\n",
        "for layer in range(Nlayers):\n",
        "    W.append(cp.asarray((b[layer] - a[layer]) * np.random.random_sample((Nnrn[layer], layerSize[layer][0],layerSize[layer][1])) + a[layer])) \n",
        "    firingTime.append(cp.asarray(np.zeros(Nnrn[layer])))\n",
        "    Spikes.append(cp.asarray(np.zeros((layerSize[layer+1][0],layerSize[layer+1][1],tmax+1))))\n",
        "    X.append(cp.asarray(np.mgrid[0:layerSize[layer+1][0],0:layerSize[layer+1][1]]))\n",
        "\n",
        "\n",
        "SpikeList=[SpikeImage]+Spikes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "343TMDV6soTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "31ec0e59-3f82-4c3c-d9b3-60cc9a5494b1"
      },
      "source": [
        "# Start learning\n",
        "for epoch in range(Nepoch):\n",
        "    start_time = time.time()\n",
        "    correct=cp.zeros(NumOfClasses)\n",
        "    FiringFrequency=cp.zeros((NhidenNeurons))\n",
        "\n",
        "    # Start an epoch\n",
        "    for iteration in range(len(x_train)): \n",
        "        #converting input image into spiking image\n",
        "        SpikeImage[:,:,:]=0\n",
        "        SpikeImage[x[0],x[1],x_train[iteration]] = 1\n",
        "\n",
        "        #Feedforward path\n",
        "        for layer in range(Nlayers):\n",
        "            Voltage=cp.cumsum(cp.tensordot(W[layer], SpikeList[layer]),1) # Computing the voltage\n",
        "            Voltage[:,tmax]=thr[layer]+1 # Forcing the fake spike\n",
        "            firingTime[layer] = cp.argmax(Voltage>thr[layer],axis=1).astype(float)+1   # Findign the first threshold crossing  \n",
        "            firingTime[layer][firingTime[layer]>tmax]=tmax # Forcing the fake spike\n",
        "                \n",
        "            Spikes[layer][:,:,:]=0   \n",
        "            Spikes[layer][X[layer][0],X[layer][1],firingTime[layer].reshape(Nnrn[layer],1).astype(int)]=1 #converting firing times to spikes\n",
        "\n",
        "        \n",
        "        FiringFrequency =  FiringFrequency + (firingTime[0] < tmax) # FiringFrequency is used to find dead neurons\n",
        "\n",
        "        #Computing the relative target firing times\n",
        "        winner=np.argmin(firingTime[Nlayers-1]) \n",
        "        minFiring=min(firingTime[layer])\n",
        "        if minFiring == tmax:          \n",
        "            target[:]=minFiring\n",
        "            target[x_train_labels[iteration]]=minFiring-gamma\n",
        "            target=target.astype(int)\n",
        "        else:\n",
        "            target[:]=firingTime[layer][:]\n",
        "            toChange=(firingTime[layer]-minFiring)<gamma\n",
        "            target[toChange]=min(minFiring+gamma,tmax)\n",
        "            target[x_train_labels[iteration]]=minFiring\n",
        "          \n",
        "\n",
        "        #Backward path\n",
        "        layer= Nlayers-1 # Output layer\n",
        "\n",
        "        delta_o=(target-firingTime[layer])/tmax # Error in the ouput layer\n",
        "\n",
        "        #Gradient normalization\n",
        "        norm=cp.linalg.norm(delta_o)\n",
        "        if (norm!=0):\n",
        "            delta_o=delta_o/norm\n",
        "            \n",
        "        if Dropout[layer]>0:\n",
        "                firingTime[layer][cp.asarray(np.random.permutation(Nnrn[layer])[:Dropout[layer]])]=tmax\n",
        "        \n",
        "        # Updating hidden-output weights\n",
        "        hasFired_o=firingTime[layer-1]<firingTime[layer][:, cp.newaxis] # To find which hidden neurons has fired before the ouput neurons\n",
        "        W[layer][:,:,0]-=(delta_o[:, cp.newaxis]*hasFired_o*lr[layer]) # Update hidden-ouput weights \n",
        "        W[layer]-=lr[layer]*lamda[layer]*W[layer] # Weight regularization\n",
        "\n",
        "        # Backpropagating error to hidden neurons\n",
        "        delta_h=(cp.multiply(delta_o[:, cp.newaxis]*hasFired_o, W[layer][:,:,0])).sum(axis=0) #Backpropagated errors from ouput layer to hidden layer\n",
        "        \n",
        "\n",
        "        layer= Nlayers-2 # Hidden layer     \n",
        "        \n",
        "        #Gradient normalization\n",
        "        norm=cp.linalg.norm(delta_h)\n",
        "        if (norm!=0):\n",
        "            delta_h=delta_h/norm\n",
        "        # Updating input-hidden weights\n",
        "        hasFired_h=x_train[iteration]<firingTime[layer][:, cp.newaxis, cp.newaxis] # To find which input neurons has fired before the hidden neurons\n",
        "        W[layer]-=lr[layer]*delta_h[:, cp.newaxis, cp.newaxis]*hasFired_h # Update input-hidden weights \n",
        "        W[layer]-=lr[layer]*lamda[layer]*W[layer] # Weight regularization\n",
        "\n",
        "    #Evaluating on test samples\n",
        "    correct=0 \n",
        "    for iteration in range(len(x_test)):        \n",
        "        SpikeImage[:,:,:]=0\n",
        "        SpikeImage[x[0],x[1],x_test[iteration]] = 1\n",
        "        for layer in range(Nlayers):\n",
        "            Voltage=cp.cumsum(cp.tensordot(W[layer], SpikeList[layer]),1)\n",
        "            Voltage[:,tmax]=thr[layer]+1\n",
        "            firingTime[layer] = cp.argmax(Voltage>thr[layer],axis=1).astype(float)+1     \n",
        "            firingTime[layer][firingTime[layer]>tmax]=tmax\n",
        "            Spikes[layer][:,:,:]=0   \n",
        "            Spikes[layer][X[layer][0],X[layer][1],firingTime[layer].reshape(Nnrn[layer],1).astype(int)]=1\n",
        "        minFiringTime=firingTime[Nlayers-1].min()\n",
        "        if minFiringTime==tmax:\n",
        "            V=np.argmax(Voltage[:,tmax-3])\n",
        "            if V==x_test_labels[iteration]:\n",
        "              correct+=1\n",
        "        else:\n",
        "            if firingTime[layer][x_test_labels[iteration]]==minFiringTime:\n",
        "                correct+=1           \n",
        "    testPerf=correct/len(x_test)\n",
        "   \n",
        "   \n",
        "    #Evaluating on train samples\n",
        "    correct=0 \n",
        "    for iteration in range(len(x_train)):        \n",
        "        SpikeImage[:,:,:]=0\n",
        "        SpikeImage[x[0],x[1],x_train[iteration]] = 1\n",
        "        for layer in range(Nlayers):\n",
        "            Voltage=cp.cumsum(cp.tensordot(W[layer], SpikeList[layer]),1)\n",
        "            Voltage[:,tmax]=thr[layer]+1\n",
        "            firingTime[layer] = cp.argmax(Voltage>thr[layer],axis=1).astype(float)+1     \n",
        "            firingTime[layer][firingTime[layer]>tmax]=tmax      \n",
        "            Spikes[layer][:,:,:]=0   \n",
        "            Spikes[layer][X[layer][0],X[layer][1],firingTime[layer].reshape(Nnrn[layer],1).astype(int)]=1               \n",
        "        minFiringTime=firingTime[Nlayers-1].min()\n",
        "        if minFiringTime==tmax:\n",
        "            V=np.argmax(Voltage[:,tmax-3])\n",
        "            if V==x_train_labels[iteration]:\n",
        "              correct+=1\n",
        "        else:\n",
        "            if firingTime[layer][x_train_labels[iteration]]==minFiringTime:\n",
        "                correct+=1\n",
        "    trainPerf=correct/len(x_train)  \n",
        "\n",
        "    \n",
        "    print('epoch= ', epoch, 'Perf_train= ',trainPerf, 'Perf_test= ',testPerf)\n",
        "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "        \n",
        "    #To save the weights\n",
        "    if saving:\n",
        "      np.save(\"weights\", W, allow_pickle=True)\n",
        "      if testPerf>best_perf:\n",
        "        np.save(\"weights_best\", W, allow_pickle=True)\n",
        "        best_perf=val\n",
        "\n",
        "    #To find and reset dead neurons    \n",
        "    ResetCheck = FiringFrequency <0.001*len(x_train)    \n",
        "    ToReset = [i for i in range(NhidenNeurons) if ResetCheck[i]]\n",
        "    for i in ToReset:\n",
        "         W[0][i]=cp.asarray((b[0] - a[0]) * np.random.random_sample((layerSize[0][0],layerSize[0][1])) + a[0]) #r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch=  0 Perf_train=  0.35484272037796843 Perf_test=  0.3639980109398309\n",
            "--- 71.69661593437195 seconds ---\n",
            "epoch=  1 Perf_train=  0.6168096481412408 Perf_test=  0.6215813028344107\n",
            "--- 70.02517938613892 seconds ---\n",
            "epoch=  2 Perf_train=  0.35210742260350614 Perf_test=  0.36051715564395825\n",
            "--- 69.69061493873596 seconds ---\n",
            "epoch=  3 Perf_train=  0.5623523560860375 Perf_test=  0.5574341123818995\n",
            "--- 70.07076120376587 seconds ---\n",
            "epoch=  4 Perf_train=  0.30187740892701725 Perf_test=  0.3162605668821482\n",
            "--- 69.86554074287415 seconds ---\n",
            "epoch=  5 Perf_train=  0.577769488996643 Perf_test=  0.5803083043262058\n",
            "--- 70.26522445678711 seconds ---\n",
            "epoch=  6 Perf_train=  0.21123958721869948 Perf_test=  0.22923918448533068\n",
            "--- 69.95342421531677 seconds ---\n",
            "epoch=  7 Perf_train=  0.3371876165609847 Perf_test=  0.3361511685728493\n",
            "--- 69.89673972129822 seconds ---\n",
            "epoch=  8 Perf_train=  0.34042024120353104 Perf_test=  0.35057185479860764\n",
            "--- 69.02004098892212 seconds ---\n",
            "epoch=  9 Perf_train=  0.2959094865100087 Perf_test=  0.2889109895574341\n",
            "--- 69.65583181381226 seconds ---\n",
            "epoch=  10 Perf_train=  0.2949148327738406 Perf_test=  0.2943809050223769\n",
            "--- 70.03903150558472 seconds ---\n",
            "epoch=  11 Perf_train=  0.47059554892453065 Perf_test=  0.45450024863252114\n",
            "--- 69.39768648147583 seconds ---\n",
            "epoch=  12 Perf_train=  0.24294417505905758 Perf_test=  0.24614619592242665\n",
            "--- 69.60780191421509 seconds ---\n",
            "epoch=  13 Perf_train=  0.2329976376973766 Perf_test=  0.24714072600696171\n",
            "--- 69.44321417808533 seconds ---\n",
            "epoch=  14 Perf_train=  0.1990550789506403 Perf_test=  0.2143212332173048\n",
            "--- 69.71372151374817 seconds ---\n",
            "epoch=  15 Perf_train=  0.3907745865970409 Perf_test=  0.38040775733465937\n",
            "--- 70.04850482940674 seconds ---\n",
            "epoch=  16 Perf_train=  0.49620788263085913 Perf_test=  0.5087021382396818\n",
            "--- 69.67580890655518 seconds ---\n",
            "epoch=  17 Perf_train=  0.34464751958224543 Perf_test=  0.35007458975634015\n",
            "--- 69.49488067626953 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA8UVj91tt8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}